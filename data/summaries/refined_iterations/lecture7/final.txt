This lecture introduces **within-subjects designs** as a counterpart to **between-groups designs**. In between-groups studies, each participant contributes data in only one condition, so individual differences add noise and require larger samples to detect effects. Within-subjects designs, by having each person experience all conditions and be compared to themselves, reduce participant-related variability and yield more powerful and efficient statistical tests.

Several forms of within-subjects designs are outlined. **Pretest–posttest** designs measure participants before and after an intervention, **repeated-measures** designs test the same people across multiple conditions, and **longitudinal** designs observe change over time. These formats require fewer participants and lower nuisance variability, but they introduce possible complications. **Demand characteristics** can arise when participants receive all conditions and infer the study’s purpose, while **carryover effects** occur when earlier conditions affect later ones through practice or fatigue. Other threats include **history effects**—outside events occurring during the study, **maturation effects**—changes due to aging or development, and **testing effects**—improvement simply from taking the same test again.

A key concern is the **order effect**, where performance depends on condition sequence. **Counterbalancing** helps distribute order effects evenly across participants. Two main strategies are discussed: **complete** and **incomplete** within-subjects designs. In complete designs, each participant experiences all possible condition orders. Examples include the **ABBA design** for two conditions, which offsets linear practice effects, and **block randomization** for three or more conditions, where every possible order is presented and repeated in random blocks. When conditions are numerous, **incomplete designs** are more practical. These include **random order with rotation**, which cycles the starting condition across participants, and the **Latin-square design**, which ensures each condition appears equally often in every sequence position and follows each other condition equally often.

In **cognitive science experiments** involving many short trials, such as visual search tasks alternating **easy** and **hard** conditions, researchers may simply intermix trials randomly to cancel order effects. Counterbalancing is still preferred when tasks are long or when random mixing could confuse participants. Finally, some manipulations—like taking a drug, undergoing surgery, or learning a lasting skill—cannot be reversed, setting practical limits on counterbalancing. The lecture concludes by reminding students that the Week 5 quiz is now available and due Friday at 11:59 p.m.
